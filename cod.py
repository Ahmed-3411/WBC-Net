{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d519e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "print(\"Setting up the dataset path...\")\n",
    "\n",
    "\n",
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    print(dirname)\n",
    "\n",
    "dataset_base_path = \"/kaggle/input/white-blood-cells-dataset\"\n",
    "train_path = os.path.join(dataset_base_path, \"Train\")\n",
    "test_path = os.path.join(dataset_base_path, \"Test-A\")\n",
    "classes = [\"Neutrophil\", \"Lymphocyte\", \"Monocyte\", \"Eosinophil\", \"Basophil\"]\n",
    "\n",
    "\n",
    "print(\"Loading and preprocessing images...\")\n",
    "\n",
    "\n",
    "def load_images_from_directory(directory_path, classes):\n",
    "    images = []\n",
    "    labels = []\n",
    "    image_paths = []\n",
    "    img_size = 128  \n",
    "    \n",
    "    for label_idx, class_name in enumerate(classes):\n",
    "        class_path = os.path.join(directory_path, class_name)\n",
    "        \n",
    "        if not os.path.exists(class_path):\n",
    "            print(f\"Warning: Path {class_path} does not exist\")\n",
    "            continue\n",
    "            \n",
    "        for img_file in tqdm(os.listdir(class_path), desc=f\"Loading {class_name}\"):\n",
    "            img_path = os.path.join(class_path, img_file)\n",
    "            try:\n",
    "                img = Image.open(img_path).convert('RGB')\n",
    "                img = img.resize((img_size, img_size))\n",
    "                images.append(np.array(img))\n",
    "                labels.append(label_idx)\n",
    "                image_paths.append(img_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {img_path}: {e}\")\n",
    "    \n",
    "    return np.array(images), np.array(labels), image_paths\n",
    "\n",
    "\n",
    "X_train_data, y_train_data, train_image_paths = load_images_from_directory(train_path, classes)\n",
    "print(f\"Loaded {len(X_train_data)} training images\")\n",
    "\n",
    "\n",
    "X_test_data, y_test_data, test_image_paths = load_images_from_directory(test_path, classes)\n",
    "print(f\"Loaded {len(X_test_data)} test images\")\n",
    "\n",
    "\n",
    "print(\"\\nData Exploration:\")\n",
    "\n",
    "train_class_counts = np.bincount(y_train_data)\n",
    "for i, count in enumerate(train_class_counts):\n",
    "    if i < len(classes):\n",
    "        print(f\"{classes[i]}: {count} training images\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.countplot(x=y_train_data)\n",
    "plt.title('Training Data Class Distribution')\n",
    "plt.xlabel('Class Index')\n",
    "plt.xticks(range(len(classes)), classes, rotation=45)\n",
    "plt.ylabel('Count')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, class_name in enumerate(classes):\n",
    "    if i < len(classes):\n",
    "        class_indices = np.where(y_train_data == i)[0]\n",
    "        if len(class_indices) > 0:\n",
    "            sample_idx = class_indices[0]\n",
    "            plt.subplot(1, len(classes), i+1)\n",
    "            plt.imshow(X_train_data[sample_idx])\n",
    "            plt.title(class_name)\n",
    "            plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"\\nPreparing data for training...\")\n",
    "\n",
    "\n",
    "X_train = X_train_data / 255.0\n",
    "X_test = X_test_data / 255.0\n",
    "\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train_data, len(classes))\n",
    "y_test = tf.keras.utils.to_categorical(y_test_data, len(classes))\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} images\")\n",
    "print(f\"Validation set: {X_val.shape[0]} images\")\n",
    "print(f\"Test set: {X_test.shape[0]} images\")\n",
    "\n",
    "print(\"\\nSetting up data augmentation...\")\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    augmented = datagen.random_transform(X_train[0])\n",
    "    plt.imshow(augmented)\n",
    "    plt.title(f'Augmented {i+1}')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nBuilding high accuracy CNN model...\")\n",
    "\n",
    "img_size = 128  \n",
    "\n",
    "def build_optimized_cnn():\n",
    "    model = Sequential([\n",
    "       \n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(img_size, img_size, 3)),\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        \n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        \n",
    "        Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "       \n",
    "        Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "        Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.4),\n",
    "        \n",
    "        Flatten(),\n",
    "        Dense(1024, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(len(classes), activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.0005),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "cnn_model = build_optimized_cnn()\n",
    "cnn_model.summary()\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint('best_wbc_model.keras', save_best_only=True, monitor='val_accuracy', mode='max'),\n",
    "    EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)\n",
    "]\n",
    "\n",
    "\n",
    "print(\"\\nTraining high accuracy CNN model...\")\n",
    "\n",
    "history = cnn_model.fit(\n",
    "    datagen.flow(X_train, y_train, batch_size=32),\n",
    "    epochs=10, \n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\nEvaluating model on test set...\")\n",
    "\n",
    "\n",
    "test_loss, test_acc = cnn_model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f\"CNN Model - Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "\n",
    "print(f\"\\nGenerating detailed metrics for the model...\")\n",
    "\n",
    "y_pred = cnn_model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true_classes, y_pred_classes, target_names=classes))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"\\nVisualizing training history...\")\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"\\nVisualizing model predictions...\")\n",
    "\n",
    "\n",
    "indices = np.random.choice(range(len(X_test)), size=10, replace=False)\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "for i, idx in enumerate(indices):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(X_test[idx])\n",
    "    plt.title(f\"True: {classes[y_true_classes[idx]]}\\nPred: {classes[y_pred_classes[idx]]}\", \n",
    "              color=('green' if y_true_classes[idx] == y_pred_classes[idx] else 'red'))\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "cnn_model.save('wbc_classification_model.keras')\n",
    "print(\"\\nModel saved as 'wbc_classification_model.keras'\")\n",
    "\n",
    "\n",
    "def predict_wbc_image(image_path, model=cnn_model):\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    img = img.resize((img_size, img_size))\n",
    "    img_array = np.array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    \n",
    "    prediction = model.predict(img_array)\n",
    "    pred_class = np.argmax(prediction, axis=1)[0]\n",
    "    \n",
    "    print(f\"Predicted class: {classes[pred_class]} with {prediction[0][pred_class]:.2%} confidence\")\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Predicted: {classes[pred_class]}\\nConfidence: {prediction[0][pred_class]:.2%}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(10, 3))\n",
    "    sns.barplot(x=classes, y=prediction[0])\n",
    "    plt.title('Prediction Probabilities')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return classes[pred_class], prediction[0]\n",
    "\n",
    "\n",
    "if len(test_image_paths) > 0:\n",
    "    sample_idx = np.random.choice(range(len(test_image_paths)))\n",
    "    print(f\"\\nSample prediction demonstration:\")\n",
    "    predict_wbc_image(test_image_paths[sample_idx])\n",
    "\n",
    "print(\"\\nProject completed successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
